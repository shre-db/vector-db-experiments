{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f84164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !docker pull qdrant/qdrant\n",
    "# !docker run -p 6333:6333 -p 6334:6334 qdrant/qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d180314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install qdrant-client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2ac924",
   "metadata": {},
   "source": [
    "## **Basic Connection and Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f600550e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collections=[]\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
    "import numpy as np\n",
    "\n",
    "# Connect to Qdrant\n",
    "client = QdrantClient(host='localhost', port=6333)\n",
    "# For cloud Qdrant, use:\n",
    "# client = QdrantClient(url='https://your-qdrant-cloud-url', api_key='your-api)\n",
    "\n",
    "# Check if server is running\n",
    "print(client.get_collections())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f5f44e",
   "metadata": {},
   "source": [
    "## **Create your first collection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43d33cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"my_collection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f780ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'my_collection' created.\n"
     ]
    }
   ],
   "source": [
    "# Create collection\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(\n",
    "        size=128,  # Dimension of the vectors\n",
    "        distance=Distance.COSINE  # Distance metric\n",
    "    ),\n",
    ")\n",
    "print(f\"Collection '{collection_name}' created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c1b87e",
   "metadata": {},
   "source": [
    "## **Insert vectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdac049b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 10 points!\n"
     ]
    }
   ],
   "source": [
    "# Sample vectors (in practice, these would be the embeddings)\n",
    "vectors = [\n",
    "    np.random.rand(128).tolist() for _ in range(10)\n",
    "]\n",
    "\n",
    "# Sample payloads (optional metadata for each vector)\n",
    "payloads = [\n",
    "    {\n",
    "        \"text\": f\"Document {i}\",\n",
    "        \"category\": f\"{np.random.choice(['science', 'tech', 'art'])}\",\n",
    "        \"year\": np.random.randint(2000, 2023),\n",
    "    } for i in range(10)\n",
    "]\n",
    "\n",
    "# Insert points into the collection\n",
    "points = [\n",
    "    PointStruct(id=i, vector=vectors[i], payload=payloads[i]) for i, (vector, payload) in enumerate(zip(vectors, payloads))\n",
    "]\n",
    "\n",
    "client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")\n",
    "\n",
    "print(f\"Inserted {len(points)} points!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095634f8",
   "metadata": {},
   "source": [
    "## **Search Vectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "13ff7400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results\n",
      "--------------\n",
      "ID: 5, Score: 0.7870749, Payload: {'text': 'Document 5', 'category': 'art', 'year': 2008}\n",
      "ID: 2, Score: 0.7851794, Payload: {'text': 'Document 2', 'category': 'art', 'year': 2005}\n",
      "ID: 6, Score: 0.7507177, Payload: {'text': 'Document 6', 'category': 'science', 'year': 2014}\n",
      "ID: 3, Score: 0.75048375, Payload: {'text': 'Document 3', 'category': 'science', 'year': 2005}\n",
      "ID: 1, Score: 0.74527514, Payload: {'text': 'Document 1', 'category': 'art', 'year': 2014}\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import models\n",
    "\n",
    "query_vector = np.random.rand(128).tolist()\n",
    "\n",
    "search_results = client.query_points(\n",
    "    collection_name=collection_name,\n",
    "    query=query_vector,\n",
    "    limit=5,  # Number of nearest neighbors to return\n",
    ")\n",
    "\n",
    "print(\"Search results\\n--------------\")\n",
    "for point in search_results.points:\n",
    "    print(f\"ID: {point.id}, Score: {point.score}, Payload: {point.payload}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1732bfc4",
   "metadata": {},
   "source": [
    "## **Filtered Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9d7792aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered search results\n",
      "-----------------------\n",
      "ID: 3, Score: 0.80162513, Payload: {'text': 'Document 3', 'category': 'science', 'year': 2005}\n",
      "ID: 4, Score: 0.78390145, Payload: {'text': 'Document 4', 'category': 'tech', 'year': 2011}\n",
      "ID: 0, Score: 0.7705504, Payload: {'text': 'Document 0', 'category': 'tech', 'year': 2014}\n",
      "ID: 6, Score: 0.7278816, Payload: {'text': 'Document 6', 'category': 'science', 'year': 2014}\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import models\n",
    "\n",
    "query_vector = np.random.rand(128).tolist()\n",
    "\n",
    "filtered_search_results = client.query_points(\n",
    "    collection_name=collection_name,\n",
    "    query=query_vector,\n",
    "    query_filter=models.Filter(\n",
    "        must=[\n",
    "            models.FieldCondition(\n",
    "                key=\"category\",\n",
    "                match=models.MatchAny(any=[\"science\", \"tech\"])\n",
    "            ),\n",
    "            models.FieldCondition(\n",
    "                key=\"year\",\n",
    "                range=models.Range(gte=2005, lte=2020)\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    limit=5,  # Number of nearest neighbors to return\n",
    ")\n",
    "\n",
    "print(\"Filtered search results\\n-----------------------\")\n",
    "for point in filtered_search_results.points:\n",
    "    print(f\"ID: {point.id}, Score: {point.score}, Payload: {point.payload}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146d6221",
   "metadata": {},
   "source": [
    "## **Batch Operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "22a8d496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch search results\n",
      "---------------------\n",
      "Results for query 1:\n",
      "  ID: 1, Score: 0.80270934, Payload: None\n",
      "  ID: 5, Score: 0.7783747, Payload: None\n",
      "  ID: 9, Score: 0.7597766, Payload: None\n",
      "  ID: 6, Score: 0.75165224, Payload: None\n",
      "  ID: 0, Score: 0.75134635, Payload: None\n",
      "  ID: 2, Score: 0.74655044, Payload: None\n",
      "  ID: 7, Score: 0.7423116, Payload: None\n",
      "  ID: 3, Score: 0.7312421, Payload: None\n",
      "  ID: 8, Score: 0.7196859, Payload: None\n",
      "  ID: 4, Score: 0.68680584, Payload: None\n",
      "Results for query 2:\n",
      "  ID: 8, Score: 0.8070893, Payload: None\n",
      "  ID: 7, Score: 0.79090357, Payload: None\n",
      "  ID: 9, Score: 0.76957846, Payload: None\n",
      "  ID: 5, Score: 0.7685976, Payload: None\n",
      "  ID: 1, Score: 0.75433356, Payload: None\n",
      "  ID: 3, Score: 0.7511483, Payload: None\n",
      "  ID: 6, Score: 0.7407177, Payload: None\n",
      "  ID: 4, Score: 0.73720425, Payload: None\n",
      "  ID: 0, Score: 0.7321327, Payload: None\n",
      "  ID: 2, Score: 0.731417, Payload: None\n",
      "Results for query 3:\n",
      "  ID: 7, Score: 0.78737617, Payload: None\n",
      "  ID: 4, Score: 0.7744959, Payload: None\n",
      "  ID: 5, Score: 0.7732902, Payload: None\n",
      "  ID: 3, Score: 0.76999635, Payload: None\n",
      "  ID: 1, Score: 0.7694602, Payload: None\n",
      "  ID: 9, Score: 0.7659551, Payload: None\n",
      "  ID: 8, Score: 0.75969136, Payload: None\n",
      "  ID: 6, Score: 0.7403376, Payload: None\n",
      "  ID: 2, Score: 0.7378564, Payload: None\n",
      "  ID: 0, Score: 0.7161432, Payload: None\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import models\n",
    "\n",
    "query_vectors = [\n",
    "    models.QueryRequest(\n",
    "        query=np.random.rand(128).tolist()\n",
    "    ) for _ in range(3)\n",
    "]\n",
    "\n",
    "batch_search_results = client.query_batch_points(\n",
    "    collection_name=collection_name,\n",
    "    requests=query_vectors,\n",
    ")\n",
    "\n",
    "print(\"Batch search results\\n---------------------\")\n",
    "for i, result in enumerate(batch_search_results):\n",
    "    print(f\"Results for query {i+1}:\")\n",
    "    for point in result.points:\n",
    "        print(f\"  ID: {point.id}, Score: {point.score}, Payload: {point.payload}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662987cb",
   "metadata": {},
   "source": [
    "## **Delete Points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3959558c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=1, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.delete(\n",
    "    collection_name=collection_name,\n",
    "    points_selector=[1, 2]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468a01b4",
   "metadata": {},
   "source": [
    "## **Collection Info and Cleanup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "aa0535af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'my_collection' info after deletion: status=<CollectionStatus.GREEN: 'green'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=None indexed_vectors_count=0 points_count=8 segments_count=8 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=128, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None, datatype=None, multivector_config=None), shard_number=1, sharding_method=None, replication_factor=1, write_consistency_factor=1, read_fan_out_factor=None, on_disk_payload=True, sparse_vectors=None), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=20000, flush_interval_sec=5, max_optimization_threads=None), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=None, strict_mode_config=StrictModeConfigOutput(enabled=False, max_query_limit=None, max_timeout=None, unindexed_filtering_retrieve=None, unindexed_filtering_update=None, search_max_hnsw_ef=None, search_allow_exact=None, search_max_oversampling=None, upsert_max_batchsize=None, max_collection_vector_size_bytes=None, read_rate_limit=None, write_rate_limit=None, max_collection_payload_size_bytes=None, max_points_count=None, filter_max_conditions=None, condition_max_size=None, multivector_config=None, sparse_config=None)) payload_schema={}\n"
     ]
    }
   ],
   "source": [
    "info = client.get_collection(collection_name=collection_name)\n",
    "print(f\"Collection '{collection_name}' info after deletion: {info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "62c11b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points in collection 'my_collection': count=8\n"
     ]
    }
   ],
   "source": [
    "# Count points\n",
    "count = client.count(collection_name=collection_name)\n",
    "print(f\"Number of points in collection '{collection_name}': {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f99e82",
   "metadata": {},
   "source": [
    "## **Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6381c512",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
    "import numpy as np\n",
    "\n",
    "# Connect to Qdrant\n",
    "client = QdrantClient(host='localhost', port=6333)\n",
    "# For cloud Qdrant, use:\n",
    "# client = QdrantClient(url='https://your-qdrant-cloud-url', api_key='your-api)\n",
    "\n",
    "# Check if server is running\n",
    "print(client.get_collections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cef71d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml3au/anaconda3/envs/vector_db/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"Artificial intelligence is transforming the world.\",\n",
    "    \"Quantum computing is the future of technology.\",\n",
    "    \"The Mona Lisa is a masterpiece of art.\",\n",
    "    \"Space exploration has advanced significantly in recent years.\",\n",
    "]\n",
    "\n",
    "# Generate embeddings for the documents\n",
    "embeddings = model.encode(documents)\n",
    "\n",
    "# Create collection for text\n",
    "text_collection = \"text_similarity\"\n",
    "client.create_collection(\n",
    "    collection_name=text_collection,\n",
    "    vectors_config=VectorParams(\n",
    "        size=embeddings.shape[1],  # Dimension of the embeddings from the model\n",
    "        distance=Distance.COSINE  # Distance metric\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Insert documents with embeddings\n",
    "text_points = [\n",
    "    PointStruct(id=i, vector=embeddings[i].tolist(), payload={\"text\": documents[i]}) for i in range(len(documents))\n",
    "]\n",
    "\n",
    "client.upsert(\n",
    "    collection_name=text_collection,\n",
    "    points=text_points\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcff1b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text similarity search results\n",
      "-------------------------------\n",
      "ID: 2, Score: 0.5982033, Text: Quantum computing is the future of technology.\n",
      "ID: 1, Score: 0.49166825, Text: Artificial intelligence is transforming the world.\n"
     ]
    }
   ],
   "source": [
    "# Search for similar documents\n",
    "query_text = \"Between AI and quantum computing, which is more transformative?\"\n",
    "query_embedding = model.encode([query_text])[0].tolist()\n",
    "search_results = client.query_points(\n",
    "    collection_name=text_collection,\n",
    "    query=query_embedding,\n",
    "    limit=2,  # Number of nearest neighbors to return\n",
    ")\n",
    "\n",
    "print(\"Text similarity search results\\n-------------------------------\")\n",
    "for point in search_results.points:\n",
    "    print(f\"ID: {point.id}, Score: {point.score}, Text: {point.payload['text']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vector_db",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
